<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Automated Upper Tract Urothelial Carcinoma Tumor Segmentation During Ureteroscopy Using Computer Vision Techniques">
  <meta property="og:title" content="Automated Upper Tract Urothelial Carcinoma Tumor Segmentation During Ureteroscopy Using Computer Vision Techniques"/>
  <meta property="og:description" content="Automated Upper Tract Urothelial Carcinoma Tumor Segmentation During Ureteroscopy Using Computer Vision Techniques"/>
  <meta property="og:url" content="https://lu-d.github.io/utuc"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <meta name="twitter:title" content="UTUC Segmentation">
  <meta name="twitter:description" content="Automated Upper Tract Urothelial Carcinoma Tumor Segmentation During Ureteroscopy Using Computer Vision Techniques">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/tempIcon.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="upper tract urothelial carcinoma computer vision artificial intelligence endoscopy ureteroscopy">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Automated Upper Tract Urothelial Carcinoma Tumor Segmentation During Ureteroscopy Using Computer Vision Techniques</title>
  <link rel="icon" type="image/x-icon" href="static/images/tempIcon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Automated Upper Tract Urothelial Carcinoma Tumor Segmentation During Ureteroscopy Using Computer Vision Techniques</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/daiwei-lu-895806162" target="_blank">Daiwei Lu<sup>1</sup></a>,</span>
                <span class="author-block">
                  Amy Reed<sup>2</sup>,</span>
                  <span class="author-block">
                    Natalie Pace<sup>2</sup>,</span>
                    <span class="author-block">
                      Amy N. Luckenbaugh<sup>2</sup>,</span>
                      <span class="author-block">
                        Maximilian Pallauf<sup>3,4</sup>,
                      </span>
                      <span class="author-block">
                        Ipek Oguz<sup>1</sup>,
                      </span>
                      <span class="author-block">
                        Nicholas Kavoussi<sup>2</sup>
                      </span>
                      </div>

                      <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>Department of Computer Science, Vanderbilt University<br><sup>2</sup>Department of Urology, 
                          Vanderbilt University Medical Center<br><sup>3</sup>Department of Urology, Johns Hopkins University<br><sup>4</sup>Department of Urology, University Hospital Salzburg, 
                          Paracelsus Medical University Salzburg, Austria<br>J. Endourology 2024</span>
                      </div>

                      <div class="column has-text-centered">
                        <!-- <div class="publication-links"> Arxiv PDF link -->
                          <span class="link-block">
                            <a href="" target="_blank"
                            class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                              <i class="fas fa-file-pdf"></i>
                            </span>
                            <span>PDF (waiting for publication)</span>
                          </a>
                        </span>

                        <!-- Supplementary PDF link -->
                        <span class="link-block">
                          <a href="https://drive.google.com/drive/folders/1SgfW9ol2jPlvK2B-YFck6UC95RLw8PBb?usp=sharing" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Models</span>
                        </a>
                      </span>

                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/Lu-D/UTUCSegmentation" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a> -->
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center>
        <img src="static/images/tempTable.png" alt="Sample Figure" class="center-image"/>
      </center>
      <h2 class="subtitle has-text-centered">
        Qualitative results of automated segmentation during endoscopic UTUC surgery demonstrating 
(left to right) the original endoscopic video image, manual segmentation performed by the surgeons (blue 
overlay), the contour of the automated segmentation (green overlay), and a heatmap prediction 
demonstrating the raw probability output per pixel. Blue and red colored pixels represent low and high 
probability of correct segmentation, respectively. a) Digital scope tumor identification, b) area of ablated 
tumor, c) fiberoptic scope tumor identification, d) example of model performing in instance with decreased 
visibility during tumor ablation. 
*Area of hemorrhage obstructing target tissue.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Endoscopic tumor ablation of upper tract urothelial carcinoma (UTUC) allows for tumor control with the benefit of renal preservation but is impacted by intraoperative visibility. We sought to develop a computer vision model for real-time, automated segmentation of UTUC tumors to augment visualization during treatment. 
          </p>
          <p>
            We collected twenty videos of endoscopic treatment of UTUC from two institutions. Frames from each video (N=3387) were extracted and manually annotated to identify tumors and areas of ablated tumor. Three established computer vision models (U-Net, U-Net++ and UNext) were trained using these annotated frames and compared. Eighty percent of the data was used to train the models while 10% was used for both validation and testing. We evaluated the highest performing model for tumor and ablated tissue segmentation using a pixel-based analysis. The model and a video overlay depicting tumor segmentation were further evaluated intraoperatively.
          </p>
          <p>
            All twenty videos (mean 36 seconds ± 58s) demonstrated tumor identification and 12 depicted areas of ablated tumor. The U-Net model demonstrated the best performance for segmentation of both tumors (AUC-ROC of 0.96) and areas of ablated tumor (AUC-ROC of 0.90). Additionally, we implemented a working system to process real-time video feeds and overlay model predictions intraoperatively. The model was able to annotate new videos at 15 fps.
          </p>
          <p>
            Computer vision models demonstrate excellent real-time performance for automated upper tract urothelial tumor segmentation during ureteroscopy. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
       
        <img src="static/images/viewabilitycameragen2.png" alt="Camera Simulation"/>
        <h2 class="subtitle has-text-centered">
          viewability computation. The camera is placed along the ureter, and a cone (blue) originates at the camera. The surface mesh cells intersecting with the  cone are marked in yellow. Teal triangles mark the boundary between seen and unseen.
        </h2>
      </div>
      <div class="item">
       
        <img src="static/images/viewabilityphantom1.png" alt="Global Flexion"/>
        <h2 class="subtitle has-text-centered">
          Marking fURS movement range in a 3D printed PLA phantom of the renal collecting system. Red dots show the farthest bound of tip flexion within each branch. The global flexion of the scope is shown by bending to the upper-most circle.
        </h2>
      </div>
      <div class="item">
  
        <img src="static/images/viewabilityphantom2.png" alt="Local Flexion"/>
        <h2 class="subtitle has-text-centered">
          Marking fURS movement range in a 3D printed PLA phantom of the renal collecting system. Red dots show the farthest bound of tip flexion within each branch. The local flexion ability of the scope in the upper pole calyx.
       </h2>
     </div>

  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->

<!-- <section class="section is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Viewability Study</h2>
          <center>
          <img src="static/images/expertlabels.png" alt="Expert Labels" class="center-image"/>
          </center>
          <div class="level-set has-text-justified">
            <p>
              We evaluated our system by tasking an experienced surgeon with watching their endoscopy recordings and manually marking on the extracted surface mesh which regions were not visuzalized. These points are delineated with the red dots.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Predictions</h2>
          <center>
          <img src="static/images/predictions.png" alt="AVA Predictions" class="center-image blend-img-background"/>
          </center>
          <div class="level-set has-text-justified">
            <p>
              All rendering and viewability calculations are done through the Visualization ToolKit (VTK).
            </p>
            <p>
              Beginning from the closest skeleton point to this ureter entry point, we construct a breadth-first search tree of the directed skeleton edges. At each edge, the angle from the previous edge is considered. If it exceeds the global flexion angle, then that edge and its successors are no longer considered. The result of this is an ordered traversal tree representing everywhere the endoscope can travel along the skeleton.
            </p>
            <p>
              The tree is traversed edge by edge inward from the ureter. Along each edge, camera positions are sampled at a constant step size. Camera directions are then generated to be evenly distributed along a spherical sector using a Fibonacci lattice. The sector size is determined by the local flexion angle. Along each camera direction, a cone is then placed to represent the camera view with the scope tip lying on the skeleton edge. The cone angle is determined by the camera FOV determined from the scope. Finally, the surface mesh is intersected with each cone and the overlapping VTK cells are marked as ``seen''. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->




<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>To be updated when published.</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
